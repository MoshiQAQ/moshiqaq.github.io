<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zhaoyang Yu</title>
    <meta name="description" content="Zhaoyang Yu - Researcher focusing on LLM agents and reasoning.">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <div class="top-nav" id="nav">
        <a href="#bio">Bio</a>
        <span>/</span>
        <a href="#publications">Publications</a>
        <span>/</span>
        <a href="#projects">Projects</a>
        <span>/</span>
        <a href="#experience">Experience</a>
        <span>/</span>
        <a href="#service">Service</a>
        <span>/</span>
        <a href="#talks">Talks</a>
        <span>/</span>
        <a href="#blog">Blogs</a>
    </div>

    <main class="container">
        <section id="bio" class="section">
            <div class="intro">
                <div class="intro-top">
                    <div class="intro-photo">
                        <img src="assets/img/yzy.jpg" alt="Portrait of Zhaoyang Yu">
                    </div>
                    <div class="intro-summary">
                        <h1>Zhaoyang Yu</h1>
                        <p class="tagline">DeepWisdom</p>
                        <ul class="contact-links">
                            <li><a href="mailto:zhaoyangyu713@gmail.com">Email</a></li>
                            <li><a href="https://github.com/MoshiQAQ" target="_blank" rel="noopener noreferrer">GitHub</a></li>
                            <li><a href="https://scholar.google.com/citations?user=max6MlEAAAAJ" target="_blank" rel="noopener noreferrer">GS</a></li>
                            <li><a href="https://x.com/ZhaoyangYu22356" target="_blank" rel="noopener noreferrer">X</a></li>
                            <li><a href="assets/cv/Zhaoyang_PhD_CV.pdf" target="_blank" rel="noopener noreferrer">CV</a></li>
                        </ul>
                    </div>
                </div>
                <div class="intro-body">
                    <p>I am a Research Intern at <a href="https://www.deepwisdom.ai/" target="_blank" rel="noopener noreferrer">DeepWisdom</a>, where I work with <a href="https://alexanderwu.mgx.world/" target="_blank" rel="noopener noreferrer">Chenglin Wu</a>, <a href="https://didiforgithub.github.io/" target="_blank" rel="noopener noreferrer">Jiayi Zhang</a>, and <a href="https://evanwu1125.github.io/" target="_blank" rel="noopener noreferrer">Yifan Wu</a>. I am fortunate to collaborate with <a href="https://mila.quebec/en/directory/bang-liu" target="_blank" rel="noopener noreferrer">Bang Liu</a> and <a href="https://luoyuyu.vip/" target="_blank" rel="noopener noreferrer">Yuyu Luo</a>.</p>
                    <p>I received my B.E. from the <a href="http://ai.ruc.edu.cn/english/index.htm" target="_blank" rel="noopener noreferrer">Renmin University of China</a>. As a Co-Founder of <a href="https://github.com/FoundationAgents/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a> and a member of <a href="https://foundationagents.org/" target="_blank" rel="noopener noreferrer">Foundation Agents</a>, I am committed to advancing open-source agent infrastructure and research. Currently, my research interest focuses on developing LLM-based agents that can operate effectively across diverse environments and tasks.</p>
                    <div class="intro-focus">
                        <h3 class="intro-subheading">Focus</h3>
                        <ul class="focus-list">
                            <li><strong>Agent learning.</strong> Learning is key to cross-environment capabilities. Learning environment dynamics requires complex optimization approaches, signals, and targets beyond model parameters, like <a href="#pub-aflow">AFlow</a> optimizing decision workflows and <a href="#pub-spo">SPO</a> exploring new reward signals for prompt optimization.</li>
                            <li><strong>Decision-making.</strong> Human decision-making naturally enables cross-environment learning and generalization. We explore agent decision structures that mirror human reasoning, potentially unlocking similar learning advantages. <a href="#pub-aot">AoT</a> atomizes reasoning to address context limitations, while <a href="#pub-recode">ReCode</a> unifies planning and action for more natural decision-making.</li>
                            <li><strong>Environment scaling.</strong> Agent environments are inevitably simplified versions of human environments, lacking complexity, dynamics, and rich reward signals that make agent learning inherently challenging. We aim to scale environments, like <a href="#pub-autoenv">AutoEnv</a>, to provide richer dynamics, diverse distributions, and more abundant rewards for effective learning.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <section id="publications" class="section">
            <h2>Selected Publications</h2>
            <ul class="item-list publication-list">
                <li id="pub-recode">
                    <p class="item-title"><strong>ReCode: Unify Plan and Action for Universal Granularity Control.</strong></p>
                    <p class="item-authors"><strong>Zhaoyang Yu</strong>, Jiayi Zhang, Huixue Su, Yufan Zhao, Yifan Wu, Mingyi Deng, Jinyu Xiang, Yizhang Lin, Lingxiao Tang, Yuyu Luo, Bang Liu, Chenglin Wu.</p>
                    <!-- <p class="item-meta">ArXiv: <a href="https://arxiv.org/abs/2510.23564" target="_blank" rel="noopener noreferrer">2510.23564</a>. <span class="item-note">Under Review</span></p> -->
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2510.23564" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/ReCode" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-autoenv">
                    <p class="item-title"><strong>AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning.</strong></p>
                    <p class="item-authors">Jiayi Zhang, Yiran Peng, Fanqi Kong, Yang Cheng, Yifan Wu, <strong>Zhaoyang Yu</strong>, Jinyu Xiang, Jianhao Ruan, Jinlin Wang, Maojia Song, HongZhang Liu, Xiangru Tang, Bang Liu, Chenglin Wu, Yuyu Luo.</p>
                    <!-- <p class="item-meta">ArXiv: <a href="https://arxiv.org/abs/2510.23564" target="_blank" rel="noopener noreferrer">2510.23564</a>. <span class="item-note">Under Review</span></p> -->
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2511.19304" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/AutoEnv" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-aflow">
                    <p class="item-title"><strong>AFlow: Automating Agentic Workflow Generation.</strong></p>
                    <p class="item-authors">Jiayi Zhang, Jinyu Xiang, <strong>Zhaoyang Yu</strong>, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu.</p>
                    <p class="item-meta"><span class="item-venue">The International Conference on Learning Representations (ICLR), 2025.</span> <span class="item-badge">Oral</span></p>
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2410.10762" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/AFlow" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-spo">
                    <p class="item-title"><strong>Self-supervised Prompt Optimization.</strong></p>
                    <p class="item-authors">Jinyu Xiang, Jiayi Zhang, <strong>Zhaoyang Yu</strong>, Xinbing Liang, Fengwei Teng, Jinhao Tu, Fashen Ren, Xiangru Tang, Sirui Hong, Chenglin Wu, Yuyu Luo.</p>
                    <p class="item-meta"><span class="item-venue">The Conference on Empirical Methods in Natural Language Processing (EMNLP), 2025.</span></p>
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2502.06855" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/SPO" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-aot">
                    <p class="item-title"><strong>Atom of Thoughts for Markov LLM Test-Time Scaling.</strong></p>
                    <p class="item-authors">Fengwei Teng, <strong>Zhaoyang Yu</strong>, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo.</p>
                    <p class="item-meta"><span class="item-venue">The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS), 2025.</span></p>
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2502.12018" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/qixucen/atom" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-foundation-agents">
                    <p class="item-title"><strong>Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems.</strong></p>
                    <p class="item-authors">Bang Liu, Xinfeng Li, Jiayi Zhang, Jinlin Wang, Tanjin He, Sirui Hong, Hongzhang Liu, Shaokun Zhang, Kaitao Song, Kunlun Zhu, Yuheng Cheng, Suyuchen Wang, Xiaoqiang Wang, Yuyu Luo, Haibo Jin, Peiyan Zhang, Ollie Liu, Jiaqi Chen, Huan Zhang, <strong>Zhaoyang Yu</strong>, Haochen Shi, Boyan Li, Dekun Wu, Fengwei Teng, Xiaojun Jia, Jiawei Xu, Jinyu Xiang, Yizhang Lin, Tianming Liu, Tongliang Liu, Yu Su, Huan Sun, Glen Berseth, Jianyun Nie, Ian Foster, Logan Ward, Qingyun Wu, Yu Gu, Mingchen Zhuge, Xiangru Tang, Haohan Wang, Jiaxuan You, Chi Wang, Jian Pei, Qiang Yang, Xiaoliang Qi, Chenglin Wu.</p>
                    <!-- <p class="item-meta">ArXiv: <a href="https://arxiv.org/abs/2504.01990" target="_blank" rel="noopener noreferrer">2504.01990</a>.</p> -->
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2504.01990" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/awesome-foundation-agents" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-vrbench">
                    <p class="item-title"><strong>Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks.</strong></p>
                    <p class="item-authors">Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, <strong>Zhaoyang Yu</strong>, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu</p>
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2511.15065" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/ImYangC7/VR-Bench" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-interactcomp">
                    <p class="item-title"><strong>InteractComp: Evaluating Search Agents With Ambiguous Queries.</strong></p>
                    <p class="item-authors">Mingyi Deng, Lijun Huang, Yani Fan, Jiayi Zhang, Fashen Ren, Jinyi Bai, Fuzhen Yang, Dayi Miao, <strong>Zhaoyang Yu</strong>, Yifan Wu, Yanfei Zhang, Fengwei Teng, Yingjia Wan, Song Hu, Yude Li, Xin Jin, Conghao Hu, Haoyu Li, Qirui Fu, Tai Zhong, Xinyu Wang, Xiangru Tang, Nan Tang, Chenglin Wu, Yuyu Luo</p>
                    <!-- <p class="item-meta">ArXiv: <a href="https://arxiv.org/abs/2510.24668" target="_blank" rel="noopener noreferrer">2510.24668</a>. <span class="item-note">Under Review</span></p> -->
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2510.24668" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/FoundationAgents/InteractComp" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
                <li id="pub-visjudge">
                    <p class="item-title"><strong>VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations.</strong></p>
                    <p class="item-authors">Yupeng Xie, Zhiyang Zhang, Yifan Wu, Sirong Lu, Jiayi Zhang, <strong>Zhaoyang Yu</strong>, Jinlin Wang, Sirui Hong, Bang Liu, Chenglin Wu, Yuyu Luo.</p>
                    <!-- <p class="item-meta">ArXiv: <a href="https://arxiv.org/abs/2510.22373" target="_blank" rel="noopener noreferrer">2510.22373</a>.</p> -->
                    <p class="item-links">
                        [<a href="https://arxiv.org/abs/2510.22373" target="_blank" rel="noopener noreferrer">paper</a>] Â·
                        [<a href="https://github.com/HKUSTDial/VisJudgeBench" target="_blank" rel="noopener noreferrer">code</a>]
                    </p>
                </li>
            </ul>
        </section>

        <section id="projects" class="section">
            <h2>Selected Projects</h2>
            <ul class="item-list projects-list">
                <!-- PROJECTS_LIST_START -->
                <li class="project-item">
                    <p class="item-title"><a href="https://github.com/FoundationAgents/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a></p>
                    <p class="project-meta">51.5k stars Â· 9k forks</p>
                    <p class="project-description">No fortress, purely open ground.  OpenManus is Coming.</p>
                </li>
                <li class="project-item">
                    <p class="item-title"><a href="https://github.com/FoundationAgents/ReCode" target="_blank" rel="noopener noreferrer">ReCode</a></p>
                    <p class="project-meta">518 stars Â· 56 forks</p>
                    <p class="project-description">Next paradigm for LLM Agent. Unify plan and action through recursive code generation for adaptive, human-like decision-making.</p>
                </li>
                <li class="project-item">
                    <p class="item-title"><a href="https://github.com/FoundationAgents/awesome-foundation-agents" target="_blank" rel="noopener noreferrer">Awesome-Foundation-Agents</a></p>
                    <p class="project-meta">1.9k stars Â· 182 forks</p>
                    <p class="project-description">About Awesome things towards foundation agents. Papers / Repos / Blogs / ...</p>
                </li>
                <li class="project-item">
                    <p class="item-title"><a href="https://github.com/FoundationAgents/AFlow" target="_blank" rel="noopener noreferrer">AFlow</a></p>
                    <p class="project-meta">375 stars Â· 79 forks</p>
                    <p class="project-description">ğŸ”¥ğŸ”¥ğŸ”¥ ICLR 2025 Oral. Automating Agentic Workflow Generation.</p>
                </li>
                <!-- PROJECTS_LIST_END -->
            </ul>
        </section>

        <section id="experience" class="section">
            <h2>Experience</h2>
            <ul class="simple-list">
                <li>
                    <strong>Research Intern, DeepWisdom</strong><br>
                    <span>Feb 2025 &ndash; Present &middot; Shenzhen</span><br>
                    <span>with <a href="https://alexanderwu.mgx.world/" target="_blank" rel="noopener noreferrer">Chenglin Wu</a>, <a href="https://didiforgithub.github.io/" target="_blank" rel="noopener noreferrer">Jiayi Zhang</a>, and <a href="https://evanwu1125.github.io/" target="_blank" rel="noopener noreferrer">Yifan Wu</a></span>
                </li>
                <li>
                    <strong>Algorithm Engineer Intern, Xiaomi</strong><br>
                    <span>Jan 2024 &ndash; Apr 2024 &middot; Beijing</span><br>
                    <span>with <a href="https://github.com/MiRoboticsLab" target="_blank" rel="noopener noreferrer">MiRoboticsLab</a></span>
                </li>
                <li>
                    <strong>Research Assistant, GeWu Lab (Renmin Univ)</strong><br>
                    <span>Jun 2022 &ndash; Aug 2023 &middot; Beijing</span><br>
                    <span>with <a href="https://dtaoo.github.io/" target="_blank" rel="noopener noreferrer">Prof. Di Hu</a></span>
                </li>
            </ul>
        </section>

        <section id="service" class="section">
            <h2>Service</h2>
            <ul class="simple-list">
                <li><strong>Reviewer</strong>: ICLR 2026; ICML 2025 MAS Workshop</li>
            </ul>
        </section>

        <section id="talks" class="section">
            <h2>Talks</h2>
            <ul class="simple-list">
                <li>
                    <strong>â€œAdvances and Challenges in Foundation Agentsâ€</strong><br>
                    <span>Invited talk at 2025 X-AGI &amp; The 18th China-R Conference, Beijing (Oct 2025)</span>
                </li>
            </ul>
        </section>

        <section id="blog" class="section">
            <h2>Blogs</h2>
            <ul class="item-list">
                <li>
                    <p class="item-title"><strong>è§„åˆ’ä¸è¡ŒåŠ¨ç»Ÿä¸€ï¼šReCode å¯¹ Agent å†³ç­–çš„é‡æ–°æ€è€ƒ</strong> <span class="item-badge">2025.11.03 Â· Chinese</span></p>
                    <p class="item-description">ç”¨ä»£ç ç»Ÿä¸€è¡¨ç¤º plan å’Œ actionï¼Œç»“åˆåŠ¨æ€å±•å¼€æœºåˆ¶ï¼Œå¯èƒ½ä¸º foundation agent çš„ learning æä¾›ä¸€ä¸ªæ›´å¥½çš„ decision-making åŸºç¡€ï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªåˆæ­¥æ¢ç´¢ã€‚</p>
                    <p class="item-links"> 
                        [<a href="https://zhuanlan.zhihu.com/p/1968634056053858629" target="_blank" rel="noopener noreferrer">read more</a>]
                    </p>
                </li>
                <li>
                    <p class="item-title"><strong>ã€å°ç±³CyberDogäºŒæ¬¡å¼€å‘ã€‘è®©ä½ çš„æœºå™¨ç‹—æœ‰è‡ªå·±çš„å°æƒ…ç»ªï¼</strong> <span class="item-badge">2022.09.14 Â· Chinese</span></p>
                    <p class="item-description">åŸºäºå°ç±³CyberDogå’Œæ–‡æ¾œé¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å®ç°äº†é“è›‹æ ¹æ®ä¸åŒåœºæ™¯è€Œåšå‡ºä¸åŒçš„å¯Œæœ‰æƒ…ç»ªåŠ¨ä½œçš„èƒ½åŠ›ã€‚ä¸‹é¢æ˜¯ä¿å§†çº§æ•™ç¨‹ï¼ˆåŸºäºPythonå®ç°ï¼‰ï¼Œæ— éœ€ROSç›¸å…³çŸ¥è¯†ï¼Œè®©ä½ çš„é“è›‹ä¹Ÿæ‹¥æœ‰è‡ªå·±çš„æƒ…ç»ªï¼</p>
                    <p class="item-links">
                        [<a href="https://zhuanlan.zhihu.com/p/525114839" target="_blank" rel="noopener noreferrer">read more</a>]
                    </p>
                </li>
            </ul>
        </section>
    </main>

    <footer class="footer">
        <p>Â© 2025 Zhaoyang Yu. Built with a clean template inspired by <a href="https://yupenghou.com/" target="_blank" rel="noopener noreferrer">Yupeng Hou</a>.</p>
    </footer>
</body>
</html>
